{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10d_FineTuning_SentimentAnalysis_HuggingFace.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMc0YuoPEYDLi8KjjO/elWs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orlandxrf/curso-dl/blob/main/notebooks/10d_FineTuning_SentimentAnalysis_HuggingFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning Análisis de Sentimientos\n",
        "Dado el conjunto de datos se desarrollará una red densa para clasificar sentimientos"
      ],
      "metadata": {
        "id": "_hTucKJsYfEs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1nG0PAy0YYhC"
      },
      "outputs": [],
      "source": [
        "# establecer parametros para almacenar y cargar el conjunto de datos del repositorio de Github\n",
        "import os\n",
        "\n",
        "URL = 'https://github.com/orlandxrf/curso-dl/blob/main/data/IMDB.zip?raw=True'\n",
        "data_folder = 'data'\n",
        "filepath = os.path.join(data_folder, 'IMDB.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Obtener el conjunto de datos"
      ],
      "metadata": {
        "id": "4or9B-3jajl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# crear carpeta para almacenar el conjunto de datos\n",
        "! mkdir {data_folder}\n",
        "# descargar conjunto de datos y alamcenar\n",
        "! wget -nc {URL} -O {filepath}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sll0mlf_aszv",
        "outputId": "9ad3ba27-d27c-473b-9965-b56e8265e7fc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "File ‘data/IMDB.zip’ already there; not retrieving.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# comprobrar\n",
        "! ls -lh data/*\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aV8rUjwbbBO",
        "outputId": "d4420ea3-a9b1-476e-a855-ed4be205f022"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 26M Apr 19 16:40 data/IMDB.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analizar conjunto de datos"
      ],
      "metadata": {
        "id": "fbNBV1eaXjZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# df = pd.read_csv('data/IMDB.zip')\n",
        "df = pd.read_csv('data/IMDB.zip', compression='zip', header=0, sep=',', quotechar='\"')\n",
        "\n",
        "# eliminar columnas 'tweet_id' y 'author'\n",
        "# df.drop('tweet_id',axis=1,inplace=True)\n",
        "# df.drop('author',axis=1,inplace=True)\n",
        "print (df.head(10))\n",
        "print (f\"\\nLongitud de tweets: {len(df):,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pijhdpXRXnAs",
        "outputId": "07db2394-8581-40b7-ea20-8ae79c789510"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "5  Probably my all-time favorite movie, a story o...  positive\n",
            "6  I sure would like to see a resurrection of a u...  positive\n",
            "7  This show was an amazing, fresh & innovative i...  negative\n",
            "8  Encouraged by the positive comments about this...  negative\n",
            "9  If you like original gut wrenching laughter yo...  positive\n",
            "\n",
            "Longitud de tweets: 50,000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sentiments = dict(pd.value_counts(df['sentiment']))\n",
        "classes = list(sentiments.keys())\n",
        "for i, sent in enumerate(sentiments):\n",
        "  print (f\"{i+1}\\t{sentiments[sent]}\\t{sent}\")\n",
        "print (f\"\\n{len(df):,} tweets\")\n",
        "\n",
        "# Graficar la distribución\n",
        "plt.figure(figsize=(15, 10))\n",
        "pd.value_counts(df['sentiment']).plot.bar(title=\"Distribución de sentimientos\")\n",
        "plt.xlabel(\"Sentimiento\", fontsize=\"15\")\n",
        "plt.ylabel(\"Tweets\", fontsize=\"15\")\n",
        "plt.xticks(rotation=0, fontsize=\"15\")\n",
        "plt.yticks(fontsize=\"15\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "id": "rJifibVZYINg",
        "outputId": "ce393f19-68d4-4de6-b796-8ecee7a636dd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\t25000\tpositive\n",
            "2\t25000\tnegative\n",
            "\n",
            "50,000 tweets\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA50AAAJnCAYAAAAUUjeBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzde7jtZV3v/c9XUIGt4BKwkjhIZIru0i1WmqZbSoU0iyQ6e8jI/VylhVtTgkTNRPdWK8kIs8eyTMWtpSaheEAM2wnZYx4wUwFPIOhCRBAQvs8f4zdlMJyLNedy3muuuXi9rmtec43f7x73uOeaXg7e63cY1d0BAACAEW6z3gsAAABg5yU6AQAAGEZ0AgAAMIzoBAAAYBjRCQAAwDCiEwAAgGFEJwA7nKo6tapOXKO5Dqiqq6pql+nxe6rqSWsx98LrXFVVBy9su01V/X1V/eoavs6rqur312q+EarqI1X10G187hlV9bg1XhIA62jX9V4AALcuVXVhku9I8o0kNyT5aJK/SnJad9+YJN395FXM9aTuPmtLY7r74iR3+PZWvXXdvdxr/H6Sd3b3K0e//nqpqlcl+Wx3n7C0rbvvta3zdfcRa7Sux2f2v40HrcV8AGw70QnAenh0d59VVXsleUiSP0ryQ0mesJYvUlW7dvc31nLO1eju49frtQFgR+H0WgDWTXd/pbvfnOSYJI+rqnsnNz+FtKr2qaq3VtUVVfXlqjpnOm311UkOSPKW6dTWZ1TVQVXVVfWrVXVxknfNbZv/h9bvqap/qaorp9Nf7zy91kOr6rPza6yqC6vqx6Y/71JVx1fVJ6vqq1V1flXtP+3rqjpk+vNeVfVXVXVZVV1UVSdU1W2mfY+vqvdV1f+uqs1V9emq2uLRvaq6b1X96/R6r0uy28L+R1XVv01/P+dW1fdvYZ6qqpdW1Renn/vf5/6+bz+t5+KqunQ6vXn3+b+Tqnra9NwvVNUTpn3HJvnFJM+YfgdvWebv7KSqOr2q/nr6Gf69qu5eVc+a5vtMVT18bp03O/25qp5YVR+b/q7OrKoD5/Z1VT25qj4x/fx/Mv2c90xyapIHTOu6YgW/l0Oq6uyq+kpVXT79XQOwBkQnAOuuu/8lyWeTPHiZ3U+b9u2b2Wm5x8+e0r+c5OLMjpreobtfNPechyS5Z5JHbOElfyXJE5N8V2an+f7xCpd6XJKfT3Jkkj2nOa5eZtzLkuyV5OBpLb+Smx/F/aEkH0+yT5IXJXllVdXiJFV1uyR/l+TVSe6c5PQkPzO3/75J/iLJryfZO8mfJXlzVd1+mTU9PMmPJrn7tLafTfKlad/J0/b7JDkkyX5Jfm/uud85PWe/JL+a5E+qalN3n5bkb5K8aPodPHqZ102SR08/w6YkH0xyZmb/DbJfkudO6/4WVfWYzH7fR2X2+z8nyd8uDHtUkvsn+f7pZ3pEd38syZOTvH9a152msbf0e3lekrdPa/zuaSwAa0B0ArCj+HxmYbXo+szi8MDuvr67z+nu3spcJ3X317r7mi3sf3V3f7i7v5bkxCQ/W9ONhrbiSUlO6O6P98z/191fmh8wzfNzSZ7V3V/t7guTvDjJL88Nu6i7X9HdNyT5y+nn+45lXu+Hk9w2yR9OP/sbknxgbv+xSf6su/9vd9/Q3X+Z5NrpeYuuT3LHJPdIUt39se7+whS7xyb57e7+cnd/NckfTD/D/HOfO63hbUmuSvJ9W//r+qZzuvvM6VTn0zMLyJO7+/okr01yUFXdaZnnPTnJC6a1fmNa133mj3ZO81wxXbv77szC+Vus4PdyfZIDk9y1u7/e3e9bxc8HwC0QnQDsKPZL8uVltv+vJP+Z5O1V9amqeuYK5vrMKvZflFnY7bOCefdP8smtjNlnmu+ihdfYb+7xJUt/6O6lI6XL3Yjorkk+txDZ8/MemORp06mlV0ynke4/Pe9muvtdSU5J8idJvlhVp1XVnpkF4B5Jzp+b4x+n7Uu+tHBt7NVbWO+WXDr352uSXD4F99LjbGG+A5P80dy6vpyksoW/y62sa2u/l2dMc/9Lze6++8Rb/pEAWCnRCcC6q6r7Z/Yf/99ydGk6KvW07j44yU8mOa6qDl/avYUpt3YkdP+5Px+Q2VGuy5N8LbMAW1rXLrl5fH0myfdsZe7Lc9NRs/nX+NxWnrecLyTZb+HU2wMW1vP87r7T3Nce3b14CmqSpLv/uLvvl+TQzE6nffq03muS3Gtujr22cDfeZadd9U+1cp9J8usLP9/u3X3uNqzrFn8v3X1Jd/9ad981s9OVX750jS4A3x7RCcC6qao9q+pRmZ1i+dfd/e/LjHnUdJOXSvKVzD5m5cZp96WZXZ+3Wr9UVYdW1R6ZXVP4hunI238k2a2qfqKqbpvkhCTz10f+eZLnVdX3Tjes+f6q2nt+4mme1yd5flXdcToV9Lgkf70N63x/ZtecPqWqbltVRyX5wbn9r0jy5Kr6oWk9/2Va+x0XJ6qq+0/jbptZXH89yY3Tx9S8IslLq+ou09j9qmpL18Mu2tbfwUqcmuRZVXWvaV17VdXRq1jXd0/XxW7191JVR1fVd0/P3ZxZtN74rdMCsFqiE4D18Jaq+mpmR7J+N8lLsuWPS/neJGdldh3h+5O8vLvfPe17QZITptMv/+cqXv/VSV6V2amZuyV5SjK7m26S/yezuPxcZnE2fzfbl2QWLm9PcmWSVybZfZn5f3N67qcyO3r7msxu+LMq3X1dZjfReXxmp5Yek+SNc/vPS/JrmZ02uzmz05Afv4Xp9swsLjdndlrplzI7dTlJfmd67j9X1ZWZ/X2v9JrNVyY5dPod/N0Kn7Mi3f2mJC9M8tppXR9OstLP8XxXko8kuaSqLp+23dLv5f5J/m9VXZXkzUme2t2fWpMfBOBWrrZ+LwYAAADYNo50AgAAMIzoBAAAYBjRCQAAwDCiEwAAgGFEJwAAAMPsut4L2Bnss88+fdBBB633MgAAANbF+eeff3l377vcPtG5Bg466KCcd955670MAACAdVFVF21pn9NrAQAAGEZ0AgAAMIzoBAAAYBjRCQAAwDCiEwAAgGFEJwAAAMOITgAAAIYRnQAAAAwjOgEAABhGdAIAADCM6AQAAGAY0QkAAMAwohMAAIBhRCcAAADDiE4AAACGEZ0AAAAMIzoBAAAYRnQCAAAwzHaNzqo6uqreXFWfq6qrqur8qvr5hTHvqape5mu3hXH7VdWbquqrVXV5VZ1SVXss85q/VlWfqKqvT693+DJjVjQXAAAAq7Prdn6945J8OslvJ7k8yZFJXlNV+3T3y+bGvTvJ8QvPvXbpD1V12yRnJrkuyc8luVOSl0zff2lu3M8nOTXJSUnel+QJSd5aVffv7g+vZi4AAABWb3tH56O7+/K5x++qqrtmFqPz0fnl7v7nW5jnsUnumeSQ7v50klTV9UleW1XP6e5PTONOSvKX3f28aczZSe6b5Jm5KShXOhcAAACrtF1Pr10IziUfTHLXVU51RJIPLEXi5O8yO1r5yCSpqoOT3D3J6+de/8Ykp0/PX/FcAAAAbJsd4UZCD0jyHwvbHl5VV09fZ1bV9y/sv0eSC+Y3dPd1ST457cvc95uNS/KxJHeuqn1XMRcAAADbYF2jc7qpz08lefHc5rOTPDXJI5Icm+SAJOdU1UFzYzYluWKZKTdP+zL3fXHc5oX9K5kLAACAbbC9r+n8pikiX5Pk77v7VUvbu/vZc8POqaqzMjsS+VvT1w6hqo7NLIpzwAEHrPNquCUHPfMf1nsJsOFdePJPrPcSYEPzXgTfHu9DG9u6HOmsqjsnOSPJRUl+8ZbGdvclSf4pyX+b27w5yV7LDN+Um45kLn1fHLdpYf9K5lpuXad192Hdfdi+++67pWEAAAC3ats9OqfPv3xrktsleVR3X72Cp/X0teSCLFxvWVW3S3Jwbro+c+n74nWZ98js7riXrWIuAAAAtsF2jc6q2jWzu8d+b5JHdvcXV/Cc70zyoCTnz20+I8n9q+rAuW0/meT2Sf4xSbr7U5ndoOjoubluMz0+YzVzAQAAsG229zWdL09yZGY3Ctq7qvae2/fBJN+X5AWZhelFmd1E6FlJbkzyh3Nj35Dkd5O8sapOzOz02Jcmec3C52qelOSvq+rCzE7RfVxmwfsL2zAXAAAAq7S9o/Ph0/c/Wmbf3ZJ8KUllFp57J/lqkvck+anuvnhpYHdfX1WPTHJKZp/DeW2S1yZ5+vyE3f23VXWHJL+T5MQkH8nslN4Pr3YuAAAAVm+7Rmd3H7SCYUeucK7PZvZxK1sb94okr1iLuQAAAFiddf2cTgAAAHZuohMAAIBhRCcAAADDiE4AAACGEZ0AAAAMIzoBAAAYRnQCAAAwjOgEAABgGNEJAADAMKITAACAYUQnAAAAw4hOAAAAhhGdAAAADCM6AQAAGEZ0AgAAMIzoBAAAYBjRCQAAwDCiEwAAgGFEJwAAAMOITgAAAIYRnQAAAAwjOgEAABhGdAIAADCM6AQAAGAY0QkAAMAwohMAAIBhRCcAAADDiE4AAACGEZ0AAAAMIzoBAAAYRnQCAAAwjOgEAABgGNEJAADAMKITAACAYUQnAAAAw4hOAAAAhhGdAAAADCM6AQAAGEZ0AgAAMIzoBAAAYBjRCQAAwDCiEwAAgGFEJwAAAMOITgAAAIYRnQAAAAwjOgEAABhGdAIAADCM6AQAAGAY0QkAAMAwohMAAIBhRCcAAADDiE4AAACGEZ0AAAAMIzoBAAAYRnQCAAAwjOgEAABgGNEJAADAMKITAACAYUQnAAAAw4hOAAAAhhGdAAAADCM6AQAAGEZ0AgAAMIzoBAAAYBjRCQAAwDCiEwAAgGFEJwAAAMOITgAAAIYRnQAAAAwjOgEAABhGdAIAADCM6AQAAGAY0QkAAMAwohMAAIBhRCcAAADDiE4AAACGEZ0AAAAMIzoBAAAYRnQCAAAwjOgEAABgGNEJAADAMKITAACAYUQnAAAAw4hOAAAAhhGdAAAADCM6AQAAGEZ0AgAAMIzoBAAAYBjRCQAAwDCiEwAAgGFEJwAAAMNs1+isqqOr6s1V9bmquqqqzq+qn19m3K9V1Seq6uvTmMOXGbNfVb2pqr5aVZdX1SlVtcfIuQAAAFid7X2k87gkVyX57SQ/meTdSV5TVb+5NGCK0FOT/FWSI5J8JMlbq+rec2Num+TMJAcm+bkkT01ydJLT5l9sLecCAABg9Xbdzq/36O6+fO7xu6rqrpnF6MumbScl+cvufl6SVNXZSe6b5JlJfmka89gk90xySHd/ehp3fZLXVtVzuvsTA+YCAABglbbrkc6F4FzywSR3TZKqOjjJ3ZO8fu45NyY5PbMjlUuOSPKBpUic/F2S65I8cq3nAgAAYNvsCDcSekCS/5j+fI/p+wULYz6W5M5Vte/cuJuN6e7rknxybo61nAsAAIBtsK7ROd3U56eSvHjatGn6fsXC0M0L+zctM2Zp3KaFsWsxFwAAANtg3aKzqg5K8pokf9/dr1qvdWyrqjq2qs6rqvMuu+yy9V4OAADADmldorOq7pzkjCQXJfnFuV1LRyH3WnjKpoX9m5cZszRu88LYtZjrW3T3ad19WHcftu+++25pGAAAwK3ado/O6fMv35rkdkke1d1Xz+1eurZy8VrKeyT5cndfNjfuZmOq6nZJDp6bYy3nAgAAYBts1+isql0zu3vs9yZ5ZHd/cX5/d38qs5sKHT33nNtMj8+YG3pGkvtX1YFz234yye2T/ONazwUAAMC22d6f0/nyJEcmeWqSvatq77l9H+zuazP7bM2/rqoLk/xTksdlFqm/MDf2DUl+N8kbq+rEzE6PfWmS1yx8ruZazgUAAMAqbe/ofPj0/Y+W2Xe3JBd2999W1R2S/E6SE5N8JLPTcD+8NLC7r6+qRyY5JbPP4bw2yWuTPH1+wrWcCwAAgNXbrtHZ3QetcNwrkrxiK2M+m9nHrWy3uQAAAFiddf2cTgAAAHZuohMAAIBhRCcAAADDiE4AAACGEZ0AAAAMIzoBAAAYRnQCAAAwjOgEAABgGNEJAADAMKITAACAYUQnAAAAw4hOAAAAhhGdAAAADCM6AQAAGEZ0AgAAMIzoBAAAYBjRCQAAwDCiEwAAgGFEJwAAAMOITgAAAIYRnQAAAAwjOgEAABhGdAIAADCM6AQAAGAY0QkAAMAwohMAAIBhRCcAAADDiE4AAACGEZ0AAAAMIzoBAAAYRnQCAAAwjOgEAABgGNEJAADAMKITAACAYUQnAAAAw4hOAAAAhhGdAAAADCM6AQAAGEZ0AgAAMIzoBAAAYBjRCQAAwDCiEwAAgGFEJwAAAMOITgAAAIYRnQAAAAwjOgEAABhGdAIAADCM6AQAAGAY0QkAAMAwohMAAIBhRCcAAADDiE4AAACGEZ0AAAAMIzoBAAAYRnQCAAAwjOgEAABgGNEJAADAMKITAACAYUQnAAAAw4hOAAAAhhGdAAAADCM6AQAAGEZ0AgAAMIzoBAAAYBjRCQAAwDCiEwAAgGFEJwAAAMOITgAAAIYRnQAAAAwjOgEAABhGdAIAADCM6AQAAGAY0QkAAMAwohMAAIBhRCcAAADDiE4AAACGEZ0AAAAMIzoBAAAYRnQCAAAwjOgEAABgGNEJAADAMKITAACAYUQnAAAAw4hOAAAAhhGdAAAADCM6AQAAGEZ0AgAAMIzoBAAAYBjRCQAAwDCiEwAAgGG2e3RW1SFV9WdV9aGquqGq3rPMmAurqhe+Lllm3KFV9c6qurqqPl9Vz62qXRbGVFUdX1Wfqaprquq9VXWfbZkLAACA1dl1HV7zXkmOTPLPSW57C+Nek+Rlc4+vm99ZVZuSnJXko0kek+R7krw4s5A+YW7oM5OcmOTpSS5IclySs6rq3t19ySrnAgAAYBXWIzrf0t1/nyRV9YYk+2xh3Be6+59vYZ4nJ9k9yVHdfWWSd1TVnklOqqoXdfeVVbVbZtH5gu4+ZXrN9ye5MMlv5Kag3Opc384PDAAAcGu13U+v7e4b12iqI5KcuRCEr80sHh8yPX5gkj2TvH7u9b+W5C3T81czFwAAAKu0I99I6Fer6rqq+kpVvaGqDlzYf4/MTpf9pu6+OMnV076lMTck+cTCcz82N2alcwEAALBK63F67Ur8fWbXfH42yT2TPDvJOVX1X7v7K9OYTUmuWOa5m6d9S2Ou6u4blhmzR1XdrruvW+FcAAAArNIOGZ3d/dS5h+dU1blJ/i3JE5L84fqs6uaq6tgkxybJAQccsM6rAQAA2DHtyKfXflN3fzjJx5P8t7nNm5PstczwTdO+pTF3WOajTzYluXo6yrnSuRbXdFp3H9bdh+27774r+0EAAABuZTZEdE56+lpyQRaut6yq/ZPskZuuz7wgyS5JDlmYa/EazpXMBQAAwCptiOisqntnFoXnz20+I8kjquqOc9uOSXJNkrOnx+cmuTLJ0XNz7ZHk0dPzVzMXAAAAq7Tdr+mcou/I6eF+SfasqsdOj9+W5L8n+aUkb03y+cxi84QkFyd51dxUpyZ5SpI3VtULkxyc5KQkL1n66JPu/npVnZzkxKranNlRy+Myi+2XrWYuAAAAVm89biR0lySnL2xbeny3JJ+Zxvxhkjsl+VKSf0xy/HwAdvfmqjo8ySmZfe7mFUlemlkszjs5s8h8VpK9k5yX5Me7+9JtmAsAAIBV2O7R2d0XJqmtDDt8hXN9NMnDtjKmkzx/+vq25gIAAGB1NsQ1nQAAAGxMohMAAIBhRCcAAADDiE4AAACGEZ0AAAAMIzoBAAAYRnQCAAAwjOgEAABgmF1XMqiqdk2yS3dfO7ft4UkOTfLe7v7XQesDAABgA1tRdCZ5XZKvJHliklTVU5L8YZJrk+xSVUd191vHLBEAAICNaqWn1/5wkrfNPX56khd39+5J/jzJ7671wgAAANj4Vhqdeye5JEmq6r8muWuSU6d9p2d2mi0AAADczEqj89IkB01/fmSSi7r7k9Pj3ZPcuMbrAgAAYCew0ms6T0/ywqr6gSRPSHLK3L77JvnEWi8MAACAjW+l0fnMJFcmuX+SP03yB3P77pfk9Wu8LgAAAHYCK4rO7v5GkuduYd9Ra7oiAAAAdhoruqazqm6oqh/cwr77VdUNa7ssAAAAdgYrvZFQ3cK+2yb5xhqsBQAAgJ3MFk+vraoDctMda5PkvlW128Kw3ZI8Lsmn135pAAAAbHS3dE3nE5I8O0lPX3+6hXHXJHnSGq8LAACAncAtRefLk7whs1NrP5TkF6fv865LcnF3XztmeQAAAGxkW4zO7r4syWVJUlV3S/KF7r5uey0MAACAjW9FNxLq7ouSVFX9j6p6ZVW9vaq+N7ONx1TVPYeuEgAAgA1pRZ/TWVV3T/KOJHslOT/JQ5Pccdr94CQ/keRXBqwPAACADWylH5nyx0kuzuxuto/IzT9C5ewkD1rbZQEAALAzWNGRzsyOZh7d3VdU1S4L+y5N8l1ruywAAAB2Bis90vn1JLtvYd9+Sa5Ym+UAAACwM1lpdL4jyfFVtdfctq6q2yf5zSRvW/OVAQAAsOGt9PTapyf5pyT/mVmAdpLfS3KvJLdLctSQ1QEAALChrfQjUz6T5AeSnJrZzYQ+mdl1nKcnuV93XzJqgQAAAGxcKz3Sme7enOTE6QsAAAC2asXRmSRVdWiS+yXZP8lfdPclVXVIkku7+6sjFggAAMDGtaLorKo7JPmLJI9Ncv30vH9MckmSP8jsMzz/56A1AgAAsEGt9O61L0nywCSHJ7ljkprb97Ykj1zjdQEAALATWOnptUcleWp3v7uqdlnYd1GSA9d2WQAAAOwMVnqkc/ckX9rCvjsmuWFtlgMAAMDOZKXR+YEkv7KFfY9Ncu7aLAcAAICdyUpPrz0xyTuq6qzMPpuzkxxZVb+dWXT+6KD1AQAAsIGt6Ehnd5+T2U2Ebp/klMxuJPScJAcn+bHu/sCwFQIAALBhrfhzOrv7n5I8uKp2T7IpyRXdffWwlQEAALDhrehIZ1UdXlV7JEl3X9PdnxecAAAAbM1Kj3S+PckNVfXBJOdMX+/r7i3d0RYAAABWHJ13yexmQQ9K8pAkT01ym6q6IFOEdvffjFkiAAAAG9VKbyT0pe5+U3c/rbvvn9k1nT+V5LIkxyb5q4FrBAAAYINa8Y2EquoOSR6Y5MHT1w8m+XqSf8jsaCcAAADczIqis6rOS/IDSS7NLDBPT/KUJP/e3T1ueQAAAGxkKz3S+QNJrk/y/iTnJvmn7v7QsFUBAACwU1jRNZ1J9kryk0k+muSoJOdW1eaqemtVPaOqfnjYCgEAANiwVnSkc/pMzrOmr1TVbZMcnuSZSU5O0kl2GbRGAAAANqgtRmdV/WiSf+3uq6bH++ammwg9OLNTbm+T5CNxIyEAAACWcUtHOt+d5AFJ/qWqPp7kkCQ3JPnXad9zM/t8zs3DVwkAAMCGdEvRWXN//tvMjma+fzrVFgAAALZqpdd0njR4HQAAAOyEthadR1bVPVYyUXf/1RqsBwAAgJ3I1qLz91Y4TycRnQAAANzM1qLzvyc5b3ssBAAAgJ3P1qLzmu7+2nZZCQAAADud26z3AgAAANh5iU4AAACG2eLptd0tSAEAAPi2CEsAAACGEZ0AAAAMIzoBAAAYRnQCAAAwjOgEAABgGNEJAADAMKITAACAYUQnAAAAw4hOAAAAhhGdAAAADCM6AQAAGEZ0AgAAMIzoBAAAYBjRCQAAwDCiEwAAgGFEJwAAAMOITgAAAIYRnQAAAAwjOgEAABhGdAIAADCM6AQAAGAY0QkAAMAwohMAAIBhRCcAAADDiE4AAACGEZ0AAAAMIzoBAAAYRnQCAAAwjOgEAABgGNEJAADAMKITAACAYbZ7dFbVIVX1Z1X1oaq6oares8yYqqrjq+ozVXVNVb23qu6zzLhDq+qdVXV1VX2+qp5bVbuMmgsAAIDVWY8jnfdKcmSSjyf5jy2MeWaSE5O8MMmjk1yV5Kyq+s6lAVW1KclZSTrJY5I8N8nTkjxn4FwAAACswnpE51u6e//uPjrJRxZ3VtVumYXiC7r7lO4+K8nRmQXhb8wNfXKS3ZMc1d3v6O5TM4vE46pqz7WeCwAAgNXb7tHZ3TduZcgDk+yZ5PVzz/lakrckOWJu3BFJzuzuK+e2vTazeHzIgLkAAABYpR3xRkL3SHJDkk8sbP/YtG9+3AXzA7r74iRXz41by7kAAABYpR0xOjcluaq7b1jYvjnJHlV1u7lxVyzz/M3TvrWeCwAAgFXaEaNzQ6iqY6vqvKo677LLLlvv5QAAAOyQdsTo3JzkDst8XMmmJFd393Vz4/Za5vmbpn1rPdfNdPdp3X1Ydx+277773uIPBAAAcGu1I0bnBUl2SXLIwvbF6y4vyML1llW1f5I95sat5VwAAACs0o4YnecmuTKzjzZJklTVHpl9xuYZc+POSPKIqrrj3LZjklyT5OwBcwEAALBKu27vF5yi78jp4X5J9qyqx06P39bdV1fVyUlOrKrNmR1pPC6zQH7Z3FSnJnlKkjdW1QuTHJzkpCQvWfrok+7++lrNBQAAwOpt9+hMcpckpy9sW3p8tyQXJjk5szB8VpK9k5yX5Me7+9KlJ3T35qo6PMkpmX3u5hVJXppZLM5by7kAAABYhe0end19YZLayphO8vzp65bGfTTJw7bXXAAAAKzOjnhNJwAAADsJ0QkAAMAwohMAAIBhRCcAAADDiE4AAACGEZ0AAAAMIzoBAAAYRnQCAAAwjOgEAABgGNEJAADAMKITAACAYUQnAAAAw4hOAAAAhhGdAAAADCM6AQAAGEZ0AgAAMIzoBAAAYBjRCQAAwDCiEwAAgGFEJwAAAMOITgAAAIYRnQAAAAwjOgEAABhGdAIAADCM6AQAAGAY0QkAAMAwohMAAIBhRCcAAADDiE4AAACGEZ0AAAAMIzoBAAAYRnQCAAAwjOgEAABgGNEJAADAMKITAACAYUQnAAAAw4hOAAAAhhGdAAAADCM6AQAAGEZ0AgAAMIzoBAAAYBjRCQAAwDCiEwAAgGFEJwAAAMOITgAAAIYRnQAAAAwjOgEAABhGdAIAADCM6AQAAGAY0QkAAMAwohMAAFh96UAAABRUSURBVIBhRCcAAADDiE4AAACGEZ0AAAAMIzoBAAAYRnQCAAAwjOgEAABgGNEJAADAMKITAACAYUQnAAAAw4hOAAAAhhGdAAAADCM6AQAAGEZ0AgAAMIzoBAAAYBjRCQAAwDCiEwAAgGFEJwAAAMOITgAAAIYRnQAAAAwjOgEAABhGdAIAADCM6AQAAGAY0QkAAMAwohMAAIBhRCcAAADDiE4AAACGEZ0AAAAMIzoBAAAYRnQCAAAwjOgEAABgGNEJAADAMKITAACAYUQnAAAAw4hOAAAAhhGdAAAADCM6AQAAGEZ0AgAAMIzoBAAAYBjRCQAAwDA7ZHRW1eOrqpf5evLcmKqq46vqM1V1TVW9t6rus8xch1bVO6vq6qr6fFU9t6p2WRizorkAAABYnV3XewFb8bAk18w9/tTcn5+Z5MQkT09yQZLjkpxVVffu7kuSpKo2JTkryUeTPCbJ9yR5cWaxfcJq5gIAAGD1dvTo/EB3X7W4sap2yywUX9Ddp0zb3p/kwiS/kZuC8slJdk9yVHdfmeQdVbVnkpOq6kXdfeUq5gIAAGCVdsjTa1fggUn2TPL6pQ3d/bUkb0lyxNy4I5KcOQXnktdmFqIPWeVcAAAArNKOHp2frKpvVNXHq+rX57bfI8kNST6xMP5j0775cRfMD+jui5NcPTdupXMBAACwSjvq6bVfyOway39JskuSn0tyalXt0d0vTbIpyVXdfcPC8zYn2aOqbtfd103jrlhm/s3TvqxiLgAAAFZph4zO7j4zyZlzm86Yrr08oar+aJ2WdTNVdWySY5PkgAMOWOfVAAAA7Jh29NNr570hyZ2THJTZUcg7LH70SWZHLa+eOzK5Ocley8y1adq3NGYlc91Md5/W3Yd192H77rvvqn8YAACAW4ONFJ099/2CzE67PWRhzOI1nBdk4brMqto/yR5z41Y6FwAAAKu0kaLzsUkuT3JRknOTXJnk6KWdVbVHkkcnOWPuOWckeURV3XFu2zGZffbn2dPjlc4FAADAKu2Q13RW1f/J7CZCH8rsKOQx09dTuvvGJF+vqpOTnFhVmzM7InlcZhH9srmpTk3ylCRvrKoXJjk4yUlJXrL0MSrdvdK5AAAAWKUdMjqTfDzJE5Psn6SSfDTJr3T3q+fGnJxZGD4ryd5Jzkvy49196dKA7t5cVYcnOSWzz928IslLMwvPrGYuAAAAVm+HjM7uPj7J8VsZ00meP33d0riPJnnYWswFAADA6mykazoBAADYYEQnAAAAw4hOAAAAhhGdAAAADCM6AQAAGEZ0AgAAMIzoBAAAYBjRCQAAwDCiEwAAgGFEJwAAAMOITgAAAIYRnQAAAAwjOgEAABhGdAIAADCM6AQAAGAY0QkAAMAwohMAAIBhRCcAAADDiE4AAACGEZ0AAAAMIzoBAAAYRnQCAAAwjOgEAABgGNEJAADAMKITAACAYUQnAAAAw4hOAAAAhhGdAAAADCM6AQAAGEZ0AgAAMIzoBAAAYBjRCQAAwDCiEwAAgGFEJwAAAMOITgAAAIYRnQAAAAwjOgEAABhGdAIAADCM6AQAAGAY0QkAAMAwohMAAIBhRCcAAADDiE4AAACGEZ0AAAAMIzoBAAAYRnQCAAAwjOgEAABgGNEJAADAMKITAACAYUQnAAAAw4hOAAAAhhGdAAAADCM6AQAAGEZ0AgAAMIzoBAAAYBjRCQAAwDCiEwAAgGFEJwAAAMOITgAAAIYRnQAAAAwjOgEAABhGdAIAADCM6AQAAGAY0QkAAMAwohMAAIBhRCcAAADDiE4AAACGEZ0AAAAMIzoBAAAYRnQCAAAwjOgEAABgGNEJAADAMKITAACAYUQnAAAAw4hOAAAAhhGdAAAADCM6AQAAGEZ0AgAAMIzoBAAAYBjRCQAAwDCiEwAAgGFEJwAAAMOITgAAAIYRnQAAAAwjOgEAABhGdAIAADCM6AQAAGAY0QkAAMAwohMAAIBhRCcAAADDiE4AAACGEZ2Tqjq0qt5ZVVdX1eer6rlVtct6rwsAAGAj23W9F7AjqKpNSc5K8tEkj0nyPUlenFmUn7COSwMAANjQROfMk5PsnuSo7r4yyTuqas8kJ1XVi6ZtAAAArJLTa2eOSHLmQly+NrMQfcj6LAkAAGDjE50z90hywfyG7r44ydXTPgAAALaB6JzZlOSKZbZvnvYBAACwDVzTuY2q6tgkx04Pr6qqj6/nemCD2yfJ5eu9CLasXrjeKwAYznvRDsz70IZw4JZ2iM6ZzUn2Wmb7pmnft+ju05KcNnJRcGtRVed192HrvQ4Abr28F8E4Tq+duSAL125W1f5J9sjCtZ4AAACsnOicOSPJI6rqjnPbjklyTZKz12dJAAAAG5/onDk1ybVJ3lhVPzZdr3lSkpf4jE7YLpyqDsB6814Eg1R3r/cadghVdWiSU5I8ILM72f55kpO6+4Z1XRgAAMAGJjoBAAAYxum1wLqpqgur6n/PPf7Zqnr8MuPeU1Vv2K6LA+BWr6qeUVUPXWZ7V9VvrMOSYENypBNYN1V13yRf6u6Lp8dvSLJPdz90YdyhSa7v7k9s/1UCcGtVVZcnOaW7T1rY/sNJPt3dl67LwmCD8TmdwLrp7g+ucNxHR68FAFaqu/95vdcAG4nTa4FvUVWvqqrzquqnquqCqvp6Vb1vOuK4NGaPqvrjqrpk2v+Bqnr4wjwPqqpzqurK6evfqurouf3fPL22ql6V5GeSPGQ6bamr6qRp3zdPr62qh0777rXwWpuq6rqqetLctgdX1dlVdXVVfamqXrHw0UgA7CDm3nt+vKo+VFVfm9577jU35jZV9cyq+s+quraq/qOqHrcwT1XV86rqi9N7z19U1c9N7x0HzY07uar+vaquqqrPVtXfVNV3zu2/MMneSZ4997700GnfN0+vraqTpvfC2yys4yemcYfMbXtSVX1kWvtFVfWMtfw7hB2V6AS25MAkL0nyvCS/kGSvJGdW1W7T/lckeUKS5yf56SSfSfIPVfWgJKmqPZO8NcmnMovJxyZ5dZI7beH1npfk3Uk+mNldpB+Q2V2kF703yReS/OzC9p+evv+f6fV/JMlZSS6ZXvu3khyZ5P9dyQ8PwLo4IMn/yuy95eeT3CXJ66qqpv0vS3JCZh9v8hNJ3pTkL6rqUXNz/FaS4zP7SLzHZva56y9a5rXukuQPpnl+K8nBSd41F48/neQrSV6Zm96X/nWZeV6X5DuSPGRh+zFJzu/u/0ySqnp6kj9N8ndJHjX9+XmuDeXWwOm1wJbsk+Qx3X1uklTV+Uk+meTxVXV2Zv8x8ITu/stp/5lJPpTkxCSPSHL3zEL1N7r7q9Ocb9/Si3X3J6vqy0luc0unLXX3jVV1emZv5s+e23VMkrd39+bp8clJzu3uY5YGVNXnkryzqu7d3R9e6V8EANvNnZP8yNI1/FMAvinJ91XVN5L8j8y99yQ5q6q+K7P3g7dW1S5JnpHk1O7+vWnM26vqbkn2n3+h7n7i0p+n570/yWeTPCjJe7v7g9NrfnYr70sfq6oPZfY+9O5pvtsneUxm/6C69A+xz07y+939nOmp76iqPZKcUFV/6mP62Jk50glsyReXgjNJuvuiJOcn+cEk909SSU6f23/j9PhB06ZPJrkqyWuq6jFVtaUjnNvidZn9B8gPJElV7ZPkYdP2TG/iD0jy+qradekryfuSXJ/kfmu4FgDWzoULN41buqb/u5McnuTGJG9a+P/2dya5zxSO+yf5ziRvXph38XGq6oiqOreqvpLkG5kFZzL7R9PVel2Sn5nWkyRHJLljktdPjx+Q5L8kOX1h7e/K7Cjpd2/Da8KGITqBLfniFrZ91/R1VXdfvbD/0iR7VNXtpyOOP57ktpm96V5WVf9QVQevwdren+TizP5VOZmdvvuNzE5ZSpJNSXZJ8vLMInPp69ppPTf7124AdhhXLDy+bvq+W2Zn4OyS2Smv8//f/qrMzt77rsyCM0kuW5jnZo+r6v6Zhehnk/xyZlH4w3OvtVqvm9b3sOnxMUnev3R39mlfknxkYe3vnrZ7X2Kn5vRaYEvusoVtH8nsmso7VNUeC+H5HUmu7u5rk2/e3e+RVbV7kh/L7BrR1+SmN/Zt0t1dVa/P7LrO4zN7cz9j7jTeK5J0kpOSvG2ZKT7/7bw+AOviy5n9A+OPZHbEc9EXc9N/2+67sG/x8U9nFqLH9PT5gVV14LYubLpE5Lwkx1TV+5I8OrP3p/m1J7NrOZf7mJWPb+trw0YgOoEtuUtVPXDums4D/v/27jzWzqKM4/j3pxhLooBsIpAIUQEDGmJIBWIQBDUIslQEoo2yCChiwAgYwAXQYFpAQBTEIJsmFAMINBiwlB2UTaIEpAq2LLKDpOyV8vjHvBcOp+eW2+VYWr6f5Kb3nXfemTm3f7z3uTPzDPAxWiKeW2hB3S7AOd39dNfX9zdUVS8AU5NsBBw2nz7nMPa/ME8BDu6SR3yStsd0pL/nkvwZWL+qjh5je5KkN7craTOdK1bVtEEVkjxASyC3I3B5z60d+qouTzv/uffA+i8PaHJB30tHdONcnp4tKLQVOi8Aa1bVpWNsT1pmGHRKGs0TwG+TfI/2ojyK9lfks6rqxSTnAj/vjiC5F9gH2ICW5IEk2wF70Za83g+sBexHexmP5m5gxyQ70ZY8PVRVA2clq+q2JPfQMhi+QMuU2+tQWtKgV4DzgWdoWRG3A46oqn8syA9DkrRkVdWMJL8EpiSZDNxKCwg3BNarqq9V1dwkxwLHJnkcuIEWcH6ka2ZkhnQacFCSE4GpwObAxAHd3g1sl+QyWp6CGT2ravr9jpZ591haIqKHe8b+dNoxYCd1M6rX0ra5rQdsVVU7D2hPWma4p1PSaO4DDqYtUZ1CC9o+W1Uvdvf3Ac4GfgBcTDtiZfuqGpnpvIc2G3oMLWvtZOAyWiA6mlO6umfQZlP3fYMxnkfbwzO1f39pN44taEuqfkP7peJQ2tEug5Y2SZLe/L5Jywj7Fdr2ibNof0y8tqfOCcBPgP1px2i9h/YuApgNUFV/AL5LywlwCW3FTO+xKyMOAZ4DLqW9l0ZNRFdVDwA30t5LUwbcn0x7r21Le2+eS5tdve4NPrO01MvrVxVIUjugG9ioqjZZ0mORJGlRJTkd+HRVLfS+TUkLz+W1kiRJWmZ0+QN2o806vkKbWdyTNrMpaQkw6JQkSdKy5DnamdEH0M7GvI8WcB6/JAclvZW5vFaSJEmSNDQmEpIkSZIkDY1BpyRJkiRpaAw6JUmSJElDY9ApSdIASfZIcluSZ5L8J8ntSX46pL7WS3JkkpUGjKGSvGsx9HFkkicWtZ1R2h7fHXwvSdI8TCQkSVKfJIfRDqCfDFwFjKMdCj+xqj44hP62B6YC61bVrJ7y1YAPADdX1SuL2MfawHur6rZFaWeUtg8ATq6qLO62JUlLP49MkSRpXgcAp1XV4T1lU5Mc9f8cRFU9Djy+mNp6EHhwcbQlSdKCcHmtJEnzWgl4pL+w+pYHJRmXZHKSB5K8lOSvST7XV2dWkuOSfDvJg91S3SkjS2mTbEmb5QSY2S2nndXde93y2iTrdNe7JzkzyeyuzYnd/UOTPJTk8SSTkrytZxzzLK9NsnKSXyV5NMmLSW5M8vG+OpXkwCTHdO0+luQXSd45Mkbg5J66leTqnuc/leSmrv1Hk5yyOJYLS5KWHgadkiTN6y/At5J8Nckq86l3PrAHcAzweeAW4JIkG/fV2xXYGtiXdkj99t0zI30d3H0/AdgM2PkNxjcJeBj4AnAdcHaS44HxwF7AicChXb8DdUHjFcA2wCHATrRZ1SuSrNFX/TvAmsBE4FhgP+DA7t6lwPHd95t1X/t3fWwIXAY80Y31h8CXaD83SdJbhHs6JUnqk+SjwEXAukABfwcuAI6rqtldna1pQduWVXVNz7PXAo9W1Re761nAXGD9qnq5KzsR2L2q1uiuR9vTuQdwJvDuqno2yTrATOCsqtqzq7MC8CQwC9igquZ25TcDM6tqt+76SOCAqlq1u94bOBXYsKr+2ZUtB8wALqyqQ7qyAq6rqi16xnURsEZVbdpdD9zTmWQKbS9s77h2Bc4DNq+qP43pP0SStFRzplOSpD5V9Tfgw8AOwClAgO8Dt/YsDd2GtgT3hiTLjXwB04FN+pq8aiTg7NwFrJ7kHQs5xOk9Y51Nm6G8ZiSw69wDrDWfNrYBbqMt6R0ZO8A1A8b/x77ru4C1xzDO8cDv+8Z1AfAy8IkxPC9JWgaYSEiSpAGq6iXa7ONUeHVm8HRgb+AkYFVgDeC/Ax6f23f9dN/1HFog+85Rnn8jg9obVDZuPm2sCmw6Sv/3jqG/+bU94n3Ao70FVTU3yZPAymN4XpK0DDDolCRpDKrq10kmAxt0RU8B/6bthVwaPQXcCnxjwL2XFlMfDwOr9xYkeTuwSte/JOktwKBTkqQ+SVavqsf6ylYDVuS1mbvptAQ7z1bV3YvY5Zzu37HMHi4u04HPAPf3f9aFMAdaNt+qerGn/CZg5ySH9yyxnUD7/eP6RexTkrSUMOiUJGledyS5mLaX8THg/bQMs88DZ3d1pgGXA9OSTALuBFYANgbGVdVhC9DfjO7f/brkO89X1R2L/jHm6xzg68DVSY4D/kWbgRwPPFJVJyxAWyNB94FJrgRmV9UM4MfA7cBFSU6l7QOdBFxuEiFJeuswkZAkSfM6GlgH+Bkt8PwRLagcX1Uz4dUzOycAZwAH0QLQ02hHhizQLF5V3UcLaicAN/DauZ1D081IbkULno+ifc6TgA8BNy9gc9fRjlI5kDa7eVrXx53AtrQlthfSgtBzgV0W/RNIkpYWHpkiSZIkSRoaZzolSZIkSUNj0ClJkiRJGhqDTkmSJEnS0Bh0SpIkSZKGxqBTkiRJkjQ0Bp2SJEmSpKEx6JQkSZIkDY1BpyRJkiRpaAw6JUmSJElD8z/U3lxCK8ALiQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocesamiento y división de los datos\n"
      ],
      "metadata": {
        "id": "MGucn7IxiJZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_label(tag):\n",
        "    return 0 if tag == \"negative\" else 1\n",
        "\n",
        "df[\"sentiment\"] = df[\"sentiment\"].apply(lambda x: convert_label(x))\n",
        "\n",
        "print (df.head(10))"
      ],
      "metadata": {
        "id": "HoS4-zFPiVSF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a35a4a23-197d-4d1d-9617-662950b0645a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review  sentiment\n",
            "0  One of the other reviewers has mentioned that ...          1\n",
            "1  A wonderful little production. <br /><br />The...          1\n",
            "2  I thought this was a wonderful way to spend ti...          1\n",
            "3  Basically there's a family where a little boy ...          0\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...          1\n",
            "5  Probably my all-time favorite movie, a story o...          1\n",
            "6  I sure would like to see a resurrection of a u...          1\n",
            "7  This show was an amazing, fresh & innovative i...          0\n",
            "8  Encouraged by the positive comments about this...          0\n",
            "9  If you like original gut wrenching laughter yo...          1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiments = dict(pd.value_counts(df['sentiment']))\n",
        "classes = list(sentiments.keys())\n",
        "for i, sent in enumerate(sentiments):\n",
        "  print (f\"{i+1}\\t{sentiments[sent]}\\t{sent}\")\n",
        "print (f\"\\n{len(df):,} tweets\")\n",
        "\n",
        "# Graficar la distribución\n",
        "plt.figure(figsize=(15, 10))\n",
        "pd.value_counts(df['sentiment']).plot.bar(title=\"Distribución de sentimientos\")\n",
        "plt.xlabel(\"Sentimiento\", fontsize=\"15\")\n",
        "plt.ylabel(\"Tweets\", fontsize=\"15\")\n",
        "plt.xticks(rotation=0, fontsize=\"15\")\n",
        "plt.yticks(fontsize=\"15\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "id": "izr-eK3honh7",
        "outputId": "3fbfc543-8960-4796-ba93-eb0d85c658bf"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\t25000\t1\n",
            "2\t25000\t0\n",
            "\n",
            "50,000 tweets\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dividir el conjunto de datos\n",
        "# train_set = df[0:40000]\n",
        "# valid_set = df[40000:45000]\n",
        "# test_set  = df[45000:50000]\n",
        "\n",
        "train_set = df[0:3000]\n",
        "valid_set = df[3000:3500]\n",
        "test_set  = df[3500:4000]"
      ],
      "metadata": {
        "id": "UKMjwPaMSNvH"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sent = dict(pd.value_counts(train_set['sentiment']))\n",
        "valid_sent = dict(pd.value_counts(valid_set['sentiment']))\n",
        "test_sent = dict(pd.value_counts(test_set['sentiment']))\n",
        "\n",
        "clases = list(train_sent.keys())\n",
        "\n",
        "print (f\">>> Train set\")\n",
        "for i, sent in enumerate(train_sent):\n",
        "  print (f\"{i+1}\\t{train_sent[sent]:,}\\t{sent}\")\n",
        "print (f\"\\n{len(train_set):,} tweets\\n\\n\")\n",
        "\n",
        "print (f\">>> Valid set\")\n",
        "for i, sent in enumerate(valid_sent):\n",
        "  print (f\"{i+1}\\t{valid_sent[sent]:,}\\t{sent}\")\n",
        "print (f\"\\n{len(valid_set):,} tweets\\n\\n\")\n",
        "\n",
        "print (f\">>> Test set\")\n",
        "for i, sent in enumerate(test_sent):\n",
        "  print (f\"{i+1}\\t{test_sent[sent]:,}\\t{sent}\")\n",
        "print (f\"\\n{len(test_set):,} tweets\\n\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUKswqKPoKJk",
        "outputId": "cf8bd851-9311-4b35-e53b-0399d5c17b74"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Train set\n",
            "1\t1,508\t1\n",
            "2\t1,492\t0\n",
            "\n",
            "3,000 tweets\n",
            "\n",
            "\n",
            ">>> Valid set\n",
            "1\t255\t0\n",
            "2\t245\t1\n",
            "\n",
            "500 tweets\n",
            "\n",
            "\n",
            ">>> Test set\n",
            "1\t280\t0\n",
            "2\t220\t1\n",
            "\n",
            "500 tweets\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crear clase para el conjunto de datos"
      ],
      "metadata": {
        "id": "8OIrH51pttga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFEyI8WguldE",
        "outputId": "b0a1793d-f52c-43f4-a483-6aa5d5781a5e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "CKEKY5oht2vp"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print (device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDWEjUV0RU6P",
        "outputId": "572f6554-0b97-44c9-aec9-fa69b93f44c3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MakeDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, reviews, sentiments, tokenizer):\n",
        "        self.reviews    = reviews # columna donde se encuentra el texto\n",
        "        self.sentiments = sentiments # columna de la clase (0 o 1)\n",
        "        self.tokenizer  = tokenizer # tokenizador de los transformers\n",
        "        self.max_len    = tokenizer.model_max_length # longitud máxima (512 para el modelo BERT)\n",
        "  \n",
        "    def __len__(self):\n",
        "        return len(self.reviews)\n",
        "  \n",
        "    def __getitem__(self, index):\n",
        "        review = str(self.reviews[index]) # obtener texto por índice\n",
        "        sentiments = self.sentiments[index] # obtener clase por índice\n",
        "\n",
        "        # codificar (tokenizar) conjunto de datos usando función: encode_plus()\n",
        "        encoded_review = self.tokenizer.encode_plus(\n",
        "            review,\n",
        "            add_special_tokens    = True,\n",
        "            max_length            = self.max_len,\n",
        "            return_token_type_ids = False,\n",
        "            return_attention_mask = True,\n",
        "            return_tensors        = \"pt\",\n",
        "            padding               = \"max_length\",\n",
        "            truncation            = True\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoded_review['input_ids'][0],\n",
        "            'attention_mask': encoded_review['attention_mask'][0],\n",
        "            'labels': torch.tensor(sentiments, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "2FGmG8A6uleQ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cargar tokenizador del modelo BERT de HuggingFace\n",
        "model_checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPM8YwTKxJWn",
        "outputId": "14b9cf7e-cdda-4cf2-bfc7-fd09bd1c4145"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Crear objetos MakeDataset para train y valid set"
      ],
      "metadata": {
        "id": "FMLq_Zu_xY5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Dataset objects for train/validation sets.\n",
        "train_set_dataset = MakeDataset(\n",
        "    reviews    = train_set.review.tolist(),\n",
        "    sentiments = train_set.sentiment.tolist(),\n",
        "    tokenizer  = tokenizer,\n",
        ")\n",
        "\n",
        "valid_set_dataset = MakeDataset(\n",
        "    reviews    = valid_set.review.tolist(),\n",
        "    sentiments = valid_set.sentiment.tolist(),\n",
        "    tokenizer  = tokenizer,\n",
        ")"
      ],
      "metadata": {
        "id": "-0SiGaWNxSCF"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Crear DataLoader del train y valid set"
      ],
      "metadata": {
        "id": "I_nj9dIzxtXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set_dataloader = torch.utils.data.DataLoader(\n",
        "    train_set_dataset,\n",
        "    batch_size  = 16,\n",
        "    num_workers = 4\n",
        ")\n",
        "\n",
        "valid_set_dataloader = torch.utils.data.DataLoader(\n",
        "    valid_set_dataset,\n",
        "    batch_size  = 16,\n",
        "    num_workers = 4\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ok4FSt8x9Tv",
        "outputId": "60861cba-691d-4648-a53c-2c52a3b7eef9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizar un batch"
      ],
      "metadata": {
        "id": "2UOWcO7fyMn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get one batch as example.\n",
        "train_data = next(iter(train_set_dataloader))\n",
        "valid_data = next(iter(valid_set_dataloader))\n",
        "\n",
        "# Print the output sizes.\n",
        "print( train_data[\"input_ids\"].size(), valid_data[\"input_ids\"].size() )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPU8-GbYyNYX",
        "outputId": "421e0376-8828-4d47-c582-63498276bea7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 512]) torch.Size([16, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargar el modelo y realizar Fine-Tuning"
      ],
      "metadata": {
        "id": "i3vQ3CCDEE2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification"
      ],
      "metadata": {
        "id": "-jn0D7V303PN"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_checkpoint = \"bert-large-uncased\"\n",
        "model_checkpoint = \"distilbert-base-uncased\"\n",
        "model = BertForSequenceClassification.from_pretrained(model_checkpoint)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqC5zHy_EM0H",
        "outputId": "82addb06-6c48-4b16-bc53-acc07a71ca6e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
            "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "Model config BertConfig {\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing BertForSequenceClassification: ['distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'vocab_transform.weight', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'vocab_transform.bias', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'vocab_projector.bias', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'vocab_projector.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.1.sa_layer_norm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.layer.5.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'pooler.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'pooler.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.11.output.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.3.attention.self.query.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'classifier.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.10.attention.self.key.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'classifier.bias', 'encoder.layer.6.attention.self.query.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT base es un modelo de 24 capas con parámetros de 330M, y es imposible entrenar sin una configuración potente.\n",
        "\n",
        "Sin embargo, se puede ajustar el modelo para que se familiarice con el conjunto de datos (IMDB) y obtener mejores resultados (esto también se conoce como \"transfer learning\").\n",
        "\n",
        "Se puede hacer \"congelando\" la mayor parte de la red y volviendo a entrenar (ajustar pesos) una pequeña parte de ella.\n",
        "\n",
        "Está comprobado que las primeras capas de las Redes Neuronales capturan características más generales de los datos, y se volverán más específicos a medida que se profundice.\n",
        "\n",
        "Entonces, se va a \"congelar\" todo el modelo BERT."
      ],
      "metadata": {
        "id": "oU3qUPkAEemo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# al ejecutar el siguiente código, se está pasando por todos los parámetros y se establece su atributo require_grad en cero.\n",
        "# significa que Huggingface no intentará optimizar estos pesos.\n",
        "# el número total de parámetros entrenables será 2050, que pertenece al classifier head en model.classifier (en lugar de model.bert).\n",
        "# ahora se puede ajustar el modelo.\n",
        "\n",
        "for name, param in model.bert.named_parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "I7Jbk3L4FX_Q"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definir las métricas"
      ],
      "metadata": {
        "id": "Sk8aAczjGItQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cargar la métricas que se usarán\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "\n",
        "# función para calcular las métricas de las predicciones\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    print ( classification_report(labels, preds) )\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ],
      "metadata": {
        "id": "fwAuTv0kGKc5"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Establecer parámetros de entrenamiento\n",
        "\n",
        "Ver más argumentos para: [*TrainingArguments*](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments)\n",
        "\n",
        "Argumentos para el [*Trainer*](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Trainer)"
      ],
      "metadata": {
        "id": "lSbPs7gVGopI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir                  = \"./sentiment-analysis\",\n",
        "    num_train_epochs            = 3,\n",
        "    per_device_train_batch_size = 128,\n",
        "    per_device_eval_batch_size  = 64,\n",
        "    warmup_steps                = 500,\n",
        "    weight_decay                = 0.01,\n",
        "    save_strategy               = \"epoch\",\n",
        "    evaluation_strategy         = \"steps\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model           = model.to(device),\n",
        "    args            = training_args,\n",
        "    train_dataset   = train_set_dataset,\n",
        "    eval_dataset    = valid_set_dataset,\n",
        "    compute_metrics = compute_metrics\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "49MY-cJiGMNY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fefc53db-120e-4241-d587-7eaab921d596"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "using `logging_steps` to initialize `eval_steps` to 500\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota**: `warmup_steps` es un parámetro que se utiliza para reducir la tasa de aprendizaje a fin de reducir el impacto de desviar el modelo del aprendizaje en la exposición repentina de nuevos conjuntos de datos.\n",
        "\n",
        "> Por ejemplo: Si se establece `warmup_steps` como `500` para una iteración de 10,000 iteraciones, para las primeras 500 iteraciones, el modelo aprenderá el corpus con una tasa de aprendizaje mínima que la tasa que se ha especificado en el modelo. A partir de la iteración 501, el modelo usará la tasa de aprendizaje tal como se da."
      ],
      "metadata": {
        "id": "eeVW9X5MLHkR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenar el modelo"
      ],
      "metadata": {
        "id": "DleVPOfFH8TI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "P9lEHZooH-EA",
        "outputId": "b4149dea-830b-4d69-be97-9b96a6f96527"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 3000\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 72\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [72/72 10:06, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./sentiment-analysis/checkpoint-24\n",
            "Configuration saved in ./sentiment-analysis/checkpoint-24/config.json\n",
            "Model weights saved in ./sentiment-analysis/checkpoint-24/pytorch_model.bin\n",
            "Saving model checkpoint to ./sentiment-analysis/checkpoint-48\n",
            "Configuration saved in ./sentiment-analysis/checkpoint-48/config.json\n",
            "Model weights saved in ./sentiment-analysis/checkpoint-48/pytorch_model.bin\n",
            "Saving model checkpoint to ./sentiment-analysis/checkpoint-72\n",
            "Configuration saved in ./sentiment-analysis/checkpoint-72/config.json\n",
            "Model weights saved in ./sentiment-analysis/checkpoint-72/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=72, training_loss=0.6992165777418349, metrics={'train_runtime': 615.034, 'train_samples_per_second': 14.633, 'train_steps_per_second': 0.117, 'total_flos': 2367999498240000.0, 'train_loss': 0.6992165777418349, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando más datos para el entrenamiento indica que para una época se tardará más de 70 horas\n",
        "\n",
        "<pre>\n",
        "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
        "  FutureWarning,\n",
        "***** Running training *****\n",
        "  Num examples = 40000\n",
        "  Num Epochs = 1\n",
        "  Instantaneous batch size per device = 128\n",
        "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
        "  Gradient Accumulation steps = 1\n",
        "  Total optimization steps = 313\n",
        " [ 3/313 13:40 < 70:39:00, 0.00 it/s, Epoch 0.01/1]\n",
        "Step\tTraining Loss\tValidation Loss\n",
        "</pre>"
      ],
      "metadata": {
        "id": "TkzkgqINQqAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Realizar predicciones con el modelo entrenado\n",
        "\n",
        "Usar el modelo `./sentiment-analysis` para realizar predicciones con el conjunto de prueba\n",
        "\n"
      ],
      "metadata": {
        "id": "ZGM8DuE5Mlgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the checkpoint\n",
        "model = BertForSequenceClassification.from_pretrained(\"./sentiment-analysis/checkpoint-72\")\n",
        "\n",
        "# Make the test set ready\n",
        "test_set_dataset = MakeDataset(\n",
        "    reviews    = test_set.review.tolist(),\n",
        "    sentiments = test_set.sentiment.tolist(),\n",
        "    tokenizer  = tokenizer,\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = \"./sentiment-analysis\",\n",
        "    do_predict = True\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model           = model,\n",
        "    args            = training_args,\n",
        "    compute_metrics = compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "hlsmenugMt05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "facaa81a-8a10-40ee-b7db-32dfd24f601b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file ./sentiment-analysis/checkpoint-72/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file ./sentiment-analysis/checkpoint-72/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ./sentiment-analysis/checkpoint-72.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# realizar predicciones\n",
        "trainer.predict(test_set_dataset)"
      ],
      "metadata": {
        "id": "pT7W1aBoNO-I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9fca3fb4-d4c4-4efe-ffa3-fed25c61d3da"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 500\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:32]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.10      0.17       280\n",
            "           1       0.43      0.88      0.58       220\n",
            "\n",
            "    accuracy                           0.44       500\n",
            "   macro avg       0.48      0.49      0.38       500\n",
            "weighted avg       0.48      0.44      0.35       500\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PredictionOutput(predictions=array([[-0.2505452 , -0.23260684],\n",
              "       [-0.24935961, -0.21330106],\n",
              "       [-0.23841059, -0.23069544],\n",
              "       [-0.22569053, -0.24053916],\n",
              "       [-0.251482  , -0.20384452],\n",
              "       [-0.24126565, -0.21559982],\n",
              "       [-0.2449054 , -0.22589241],\n",
              "       [-0.26285437, -0.21664654],\n",
              "       [-0.2462656 , -0.21956505],\n",
              "       [-0.25588185, -0.2233397 ],\n",
              "       [-0.20409629, -0.24259172],\n",
              "       [-0.27452356, -0.21895017],\n",
              "       [-0.24549039, -0.19904703],\n",
              "       [-0.2684882 , -0.23071681],\n",
              "       [-0.21374978, -0.21564737],\n",
              "       [-0.25494403, -0.22805578],\n",
              "       [-0.23678641, -0.22201404],\n",
              "       [-0.23140368, -0.22032064],\n",
              "       [-0.2769879 , -0.21615922],\n",
              "       [-0.22745834, -0.20623668],\n",
              "       [-0.24481727, -0.21417005],\n",
              "       [-0.29029363, -0.2174478 ],\n",
              "       [-0.28606367, -0.23904935],\n",
              "       [-0.2573217 , -0.21172981],\n",
              "       [-0.25625035, -0.2025674 ],\n",
              "       [-0.26671335, -0.21091112],\n",
              "       [-0.2609994 , -0.21761173],\n",
              "       [-0.26255006, -0.21988277],\n",
              "       [-0.26604274, -0.22264333],\n",
              "       [-0.2486322 , -0.23671606],\n",
              "       [-0.25174078, -0.21923812],\n",
              "       [-0.2551128 , -0.20682198],\n",
              "       [-0.2555957 , -0.22610371],\n",
              "       [-0.2534969 , -0.22384797],\n",
              "       [-0.2367298 , -0.20499867],\n",
              "       [-0.26287234, -0.21061906],\n",
              "       [-0.26579598, -0.20253678],\n",
              "       [-0.26043832, -0.20907646],\n",
              "       [-0.26997074, -0.21318284],\n",
              "       [-0.23659334, -0.21574657],\n",
              "       [-0.24555159, -0.2130379 ],\n",
              "       [-0.25304747, -0.2122043 ],\n",
              "       [-0.26640102, -0.20603141],\n",
              "       [-0.26681405, -0.24492478],\n",
              "       [-0.23301972, -0.22024448],\n",
              "       [-0.24927573, -0.21022226],\n",
              "       [-0.25386414, -0.2273563 ],\n",
              "       [-0.27308416, -0.23584016],\n",
              "       [-0.2571762 , -0.21644771],\n",
              "       [-0.22526239, -0.24788061],\n",
              "       [-0.23709387, -0.22855584],\n",
              "       [-0.24977386, -0.2120331 ],\n",
              "       [-0.25033844, -0.20534693],\n",
              "       [-0.24408375, -0.22759253],\n",
              "       [-0.22953865, -0.2307437 ],\n",
              "       [-0.22557905, -0.24170525],\n",
              "       [-0.25975594, -0.2072694 ],\n",
              "       [-0.2565366 , -0.20593527],\n",
              "       [-0.26004097, -0.21353315],\n",
              "       [-0.26245117, -0.24818735],\n",
              "       [-0.2483448 , -0.23502955],\n",
              "       [-0.27096066, -0.21204895],\n",
              "       [-0.25563672, -0.20319451],\n",
              "       [-0.2576767 , -0.22471157],\n",
              "       [-0.26791963, -0.22213688],\n",
              "       [-0.23253176, -0.2212139 ],\n",
              "       [-0.2603096 , -0.22467466],\n",
              "       [-0.24663545, -0.2139305 ],\n",
              "       [-0.24198267, -0.2153029 ],\n",
              "       [-0.23442878, -0.23063123],\n",
              "       [-0.26959956, -0.22279061],\n",
              "       [-0.26851037, -0.2114382 ],\n",
              "       [-0.26039615, -0.21120542],\n",
              "       [-0.27651662, -0.21276051],\n",
              "       [-0.26482052, -0.21558672],\n",
              "       [-0.26565245, -0.22274145],\n",
              "       [-0.24688789, -0.21569976],\n",
              "       [-0.25982347, -0.23317969],\n",
              "       [-0.26470163, -0.19672813],\n",
              "       [-0.23971716, -0.21519497],\n",
              "       [-0.269482  , -0.20666958],\n",
              "       [-0.24565649, -0.2001151 ],\n",
              "       [-0.23977211, -0.22688578],\n",
              "       [-0.2563664 , -0.22171944],\n",
              "       [-0.26266858, -0.20673002],\n",
              "       [-0.22168624, -0.22808294],\n",
              "       [-0.21946241, -0.22389401],\n",
              "       [-0.23968795, -0.21251802],\n",
              "       [-0.23520564, -0.19880725],\n",
              "       [-0.23224714, -0.225344  ],\n",
              "       [-0.24779363, -0.21811883],\n",
              "       [-0.26034218, -0.21717489],\n",
              "       [-0.24250957, -0.21911699],\n",
              "       [-0.28375095, -0.21580498],\n",
              "       [-0.23531452, -0.21656077],\n",
              "       [-0.24461095, -0.22814816],\n",
              "       [-0.2623267 , -0.21478787],\n",
              "       [-0.2632748 , -0.21456507],\n",
              "       [-0.2682293 , -0.23578258],\n",
              "       [-0.25102866, -0.22170524],\n",
              "       [-0.24986304, -0.20943518],\n",
              "       [-0.25946218, -0.22934821],\n",
              "       [-0.26568666, -0.23010892],\n",
              "       [-0.26110795, -0.23022515],\n",
              "       [-0.2207379 , -0.23313795],\n",
              "       [-0.23420577, -0.2227054 ],\n",
              "       [-0.27523988, -0.2051959 ],\n",
              "       [-0.24164264, -0.21766461],\n",
              "       [-0.26190442, -0.21973066],\n",
              "       [-0.25214192, -0.22574888],\n",
              "       [-0.23651792, -0.23202544],\n",
              "       [-0.25979432, -0.23406301],\n",
              "       [-0.24498695, -0.22311653],\n",
              "       [-0.2502488 , -0.2083009 ],\n",
              "       [-0.2270413 , -0.25734815],\n",
              "       [-0.24608465, -0.22659786],\n",
              "       [-0.23314516, -0.17929873],\n",
              "       [-0.26799083, -0.20716707],\n",
              "       [-0.24545282, -0.22106604],\n",
              "       [-0.23145051, -0.22291154],\n",
              "       [-0.24701989, -0.21360572],\n",
              "       [-0.2667677 , -0.22215366],\n",
              "       [-0.26618564, -0.2161835 ],\n",
              "       [-0.27325562, -0.22528277],\n",
              "       [-0.2239769 , -0.2074344 ],\n",
              "       [-0.24322693, -0.22349124],\n",
              "       [-0.27486768, -0.22400011],\n",
              "       [-0.24754167, -0.20852411],\n",
              "       [-0.25999707, -0.236225  ],\n",
              "       [-0.25702196, -0.22356416],\n",
              "       [-0.2272147 , -0.23277411],\n",
              "       [-0.21713412, -0.24905363],\n",
              "       [-0.23491219, -0.21632823],\n",
              "       [-0.25622824, -0.21469595],\n",
              "       [-0.2657223 , -0.19723426],\n",
              "       [-0.26988095, -0.21339808],\n",
              "       [-0.23631082, -0.23205003],\n",
              "       [-0.24413544, -0.24616994],\n",
              "       [-0.2631834 , -0.22277324],\n",
              "       [-0.26593015, -0.22355649],\n",
              "       [-0.23655032, -0.2214305 ],\n",
              "       [-0.2559354 , -0.18213008],\n",
              "       [-0.25041673, -0.22371358],\n",
              "       [-0.23780978, -0.22678325],\n",
              "       [-0.26070368, -0.22236097],\n",
              "       [-0.23165904, -0.22619519],\n",
              "       [-0.23938607, -0.23227556],\n",
              "       [-0.24881032, -0.19784304],\n",
              "       [-0.22403358, -0.22377993],\n",
              "       [-0.24247679, -0.23876159],\n",
              "       [-0.26359832, -0.2070053 ],\n",
              "       [-0.25334102, -0.20436299],\n",
              "       [-0.26620397, -0.20314437],\n",
              "       [-0.2592028 , -0.21862024],\n",
              "       [-0.26449537, -0.22441457],\n",
              "       [-0.27327505, -0.20575163],\n",
              "       [-0.22419524, -0.2335119 ],\n",
              "       [-0.27144545, -0.2073174 ],\n",
              "       [-0.23940353, -0.23408344],\n",
              "       [-0.22785415, -0.2412718 ],\n",
              "       [-0.2553309 , -0.21969223],\n",
              "       [-0.19864263, -0.24146473],\n",
              "       [-0.24590361, -0.22466809],\n",
              "       [-0.2691902 , -0.23666666],\n",
              "       [-0.22850811, -0.23941179],\n",
              "       [-0.23360701, -0.18136781],\n",
              "       [-0.24816817, -0.23080115],\n",
              "       [-0.24757974, -0.23817912],\n",
              "       [-0.26228747, -0.1982311 ],\n",
              "       [-0.23753402, -0.22002648],\n",
              "       [-0.25043097, -0.21037944],\n",
              "       [-0.27998698, -0.21793374],\n",
              "       [-0.2412947 , -0.2122434 ],\n",
              "       [-0.25380433, -0.20890881],\n",
              "       [-0.24697995, -0.22521167],\n",
              "       [-0.25439674, -0.2275567 ],\n",
              "       [-0.24372904, -0.22531581],\n",
              "       [-0.25018024, -0.23304957],\n",
              "       [-0.2721932 , -0.20528261],\n",
              "       [-0.2625358 , -0.22470321],\n",
              "       [-0.2584729 , -0.2250882 ],\n",
              "       [-0.24696545, -0.23093101],\n",
              "       [-0.25047055, -0.2666911 ],\n",
              "       [-0.21482883, -0.22732507],\n",
              "       [-0.24744475, -0.20744415],\n",
              "       [-0.250755  , -0.22054271],\n",
              "       [-0.20021006, -0.25115776],\n",
              "       [-0.23588434, -0.24207202],\n",
              "       [-0.2139875 , -0.23283567],\n",
              "       [-0.2571958 , -0.22090378],\n",
              "       [-0.26372325, -0.22147088],\n",
              "       [-0.20806281, -0.19537823],\n",
              "       [-0.2603088 , -0.2128768 ],\n",
              "       [-0.20958652, -0.22926435],\n",
              "       [-0.247041  , -0.23299105],\n",
              "       [-0.22494054, -0.2205066 ],\n",
              "       [-0.26090324, -0.22084436],\n",
              "       [-0.24768   , -0.2254781 ],\n",
              "       [-0.2594826 , -0.21154442],\n",
              "       [-0.2615987 , -0.21578026],\n",
              "       [-0.2698749 , -0.20323415],\n",
              "       [-0.19979839, -0.20183   ],\n",
              "       [-0.2462815 , -0.2157246 ],\n",
              "       [-0.26533067, -0.17939287],\n",
              "       [-0.22160758, -0.21153007],\n",
              "       [-0.2564842 , -0.21674979],\n",
              "       [-0.23916891, -0.2186079 ],\n",
              "       [-0.25741827, -0.2140726 ],\n",
              "       [-0.22997963, -0.22383873],\n",
              "       [-0.2432199 , -0.25560865],\n",
              "       [-0.2588977 , -0.22319037],\n",
              "       [-0.2682329 , -0.20323741],\n",
              "       [-0.25165913, -0.24844803],\n",
              "       [-0.2557697 , -0.21298273],\n",
              "       [-0.2434685 , -0.22482535],\n",
              "       [-0.26576778, -0.2257848 ],\n",
              "       [-0.2904611 , -0.22114661],\n",
              "       [-0.23905617, -0.21359858],\n",
              "       [-0.24691199, -0.22087827],\n",
              "       [-0.28595275, -0.21175174],\n",
              "       [-0.26304483, -0.23492359],\n",
              "       [-0.27460843, -0.2296447 ],\n",
              "       [-0.23305039, -0.23965643],\n",
              "       [-0.24185613, -0.24290755],\n",
              "       [-0.2570535 , -0.20227474],\n",
              "       [-0.24466746, -0.21354339],\n",
              "       [-0.20968571, -0.22586955],\n",
              "       [-0.22421983, -0.24447721],\n",
              "       [-0.23223726, -0.22555815],\n",
              "       [-0.2580571 , -0.2248825 ],\n",
              "       [-0.24713698, -0.22709382],\n",
              "       [-0.27069935, -0.21023542],\n",
              "       [-0.25116828, -0.23139365],\n",
              "       [-0.24258776, -0.22010896],\n",
              "       [-0.24255311, -0.23160018],\n",
              "       [-0.25122213, -0.20904173],\n",
              "       [-0.24661718, -0.21738279],\n",
              "       [-0.24959444, -0.21382736],\n",
              "       [-0.25518888, -0.21714008],\n",
              "       [-0.2862816 , -0.19708115],\n",
              "       [-0.26434663, -0.2330709 ],\n",
              "       [-0.28193444, -0.22212733],\n",
              "       [-0.24370518, -0.2290304 ],\n",
              "       [-0.2604812 , -0.21086872],\n",
              "       [-0.2582755 , -0.22007026],\n",
              "       [-0.27131686, -0.20450506],\n",
              "       [-0.25158447, -0.21427341],\n",
              "       [-0.24407016, -0.19931625],\n",
              "       [-0.26230022, -0.19988294],\n",
              "       [-0.2546622 , -0.2042789 ],\n",
              "       [-0.27823657, -0.22288737],\n",
              "       [-0.25509462, -0.2058119 ],\n",
              "       [-0.25649545, -0.2248685 ],\n",
              "       [-0.2515558 , -0.20627375],\n",
              "       [-0.20696929, -0.23512557],\n",
              "       [-0.24541482, -0.2358435 ],\n",
              "       [-0.2684954 , -0.19902316],\n",
              "       [-0.2489038 , -0.2202598 ],\n",
              "       [-0.25723976, -0.2112018 ],\n",
              "       [-0.25149545, -0.22697471],\n",
              "       [-0.27080786, -0.21791002],\n",
              "       [-0.24485774, -0.1971283 ],\n",
              "       [-0.26087573, -0.19752066],\n",
              "       [-0.27752402, -0.20953901],\n",
              "       [-0.24866322, -0.21904708],\n",
              "       [-0.23207475, -0.22220539],\n",
              "       [-0.25840867, -0.20220183],\n",
              "       [-0.23696537, -0.23416953],\n",
              "       [-0.25631204, -0.2035307 ],\n",
              "       [-0.26243412, -0.21712562],\n",
              "       [-0.25797236, -0.19450617],\n",
              "       [-0.23950633, -0.2146723 ],\n",
              "       [-0.2631803 , -0.21868432],\n",
              "       [-0.2713912 , -0.20845978],\n",
              "       [-0.2797562 , -0.20869356],\n",
              "       [-0.25695777, -0.23661277],\n",
              "       [-0.24304576, -0.23589352],\n",
              "       [-0.23919384, -0.2158436 ],\n",
              "       [-0.2741592 , -0.2090355 ],\n",
              "       [-0.2565403 , -0.2178601 ],\n",
              "       [-0.26185927, -0.21903005],\n",
              "       [-0.25245053, -0.21622403],\n",
              "       [-0.25165182, -0.21303625],\n",
              "       [-0.22827582, -0.22155645],\n",
              "       [-0.23128141, -0.23756754],\n",
              "       [-0.26002938, -0.21773021],\n",
              "       [-0.24837103, -0.22360337],\n",
              "       [-0.2671102 , -0.20666967],\n",
              "       [-0.252857  , -0.21034253],\n",
              "       [-0.2753751 , -0.21248643],\n",
              "       [-0.23939607, -0.22144346],\n",
              "       [-0.2443559 , -0.18537714],\n",
              "       [-0.25116795, -0.21495229],\n",
              "       [-0.25158268, -0.19920903],\n",
              "       [-0.28139895, -0.20705755],\n",
              "       [-0.25744292, -0.24393263],\n",
              "       [-0.22369933, -0.17081374],\n",
              "       [-0.25899002, -0.2176159 ],\n",
              "       [-0.25163615, -0.21131541],\n",
              "       [-0.26746008, -0.2075729 ],\n",
              "       [-0.23492232, -0.23995641],\n",
              "       [-0.24633121, -0.20895511],\n",
              "       [-0.25770655, -0.20923103],\n",
              "       [-0.2781942 , -0.21656579],\n",
              "       [-0.26239917, -0.20914634],\n",
              "       [-0.23076196, -0.22921188],\n",
              "       [-0.24801514, -0.21943542],\n",
              "       [-0.28320703, -0.21307471],\n",
              "       [-0.23178172, -0.21605267],\n",
              "       [-0.26967236, -0.2321234 ],\n",
              "       [-0.270864  , -0.20694287],\n",
              "       [-0.2610855 , -0.2220149 ],\n",
              "       [-0.24805032, -0.21433842],\n",
              "       [-0.2512863 , -0.2260372 ],\n",
              "       [-0.25796643, -0.21448402],\n",
              "       [-0.24044418, -0.22846618],\n",
              "       [-0.24773447, -0.20772332],\n",
              "       [-0.273713  , -0.22077973],\n",
              "       [-0.26493347, -0.22689134],\n",
              "       [-0.2584293 , -0.2117179 ],\n",
              "       [-0.2679419 , -0.20095648],\n",
              "       [-0.29090226, -0.19381405],\n",
              "       [-0.2541363 , -0.23064706],\n",
              "       [-0.23286687, -0.20276915],\n",
              "       [-0.25533155, -0.19120581],\n",
              "       [-0.21223675, -0.19834258],\n",
              "       [-0.23433436, -0.23737693],\n",
              "       [-0.24494228, -0.23152314],\n",
              "       [-0.23180622, -0.22514844],\n",
              "       [-0.24745236, -0.23051775],\n",
              "       [-0.22279035, -0.23134618],\n",
              "       [-0.26216614, -0.20909029],\n",
              "       [-0.24883984, -0.22207901],\n",
              "       [-0.22940214, -0.21206129],\n",
              "       [-0.21946985, -0.23493347],\n",
              "       [-0.26412097, -0.22172637],\n",
              "       [-0.24667293, -0.21141426],\n",
              "       [-0.254599  , -0.21470976],\n",
              "       [-0.28065568, -0.20539513],\n",
              "       [-0.23312792, -0.20277578],\n",
              "       [-0.25747755, -0.23095971],\n",
              "       [-0.26319054, -0.21328121],\n",
              "       [-0.25246483, -0.19977278],\n",
              "       [-0.24534415, -0.20446542],\n",
              "       [-0.25709012, -0.21716607],\n",
              "       [-0.2544612 , -0.2287888 ],\n",
              "       [-0.274664  , -0.21630526],\n",
              "       [-0.24848115, -0.20249514],\n",
              "       [-0.23802382, -0.23041148],\n",
              "       [-0.26471502, -0.20970218],\n",
              "       [-0.23120148, -0.20626137],\n",
              "       [-0.25030592, -0.21136856],\n",
              "       [-0.2589605 , -0.19435345],\n",
              "       [-0.23783447, -0.24763946],\n",
              "       [-0.27863994, -0.21341395],\n",
              "       [-0.26193765, -0.21861528],\n",
              "       [-0.2574211 , -0.2299445 ],\n",
              "       [-0.2649937 , -0.24169104],\n",
              "       [-0.24061604, -0.25502223],\n",
              "       [-0.28308547, -0.20990801],\n",
              "       [-0.24639489, -0.2110252 ],\n",
              "       [-0.24149692, -0.2368171 ],\n",
              "       [-0.24878037, -0.22606392],\n",
              "       [-0.2752778 , -0.20812441],\n",
              "       [-0.2626    , -0.2059087 ],\n",
              "       [-0.24662112, -0.22228202],\n",
              "       [-0.26663026, -0.21003732],\n",
              "       [-0.26500955, -0.21349739],\n",
              "       [-0.2613028 , -0.22225322],\n",
              "       [-0.24921797, -0.2173662 ],\n",
              "       [-0.24572226, -0.22707865],\n",
              "       [-0.25598627, -0.21082911],\n",
              "       [-0.25024253, -0.18704906],\n",
              "       [-0.23698321, -0.22802834],\n",
              "       [-0.2535161 , -0.23274556],\n",
              "       [-0.25805506, -0.23050147],\n",
              "       [-0.25208426, -0.21665598],\n",
              "       [-0.26392636, -0.20980544],\n",
              "       [-0.25061408, -0.22522207],\n",
              "       [-0.2471227 , -0.22184068],\n",
              "       [-0.19646277, -0.23763396],\n",
              "       [-0.2589185 , -0.22596689],\n",
              "       [-0.25812805, -0.20605347],\n",
              "       [-0.26785588, -0.22218026],\n",
              "       [-0.26246992, -0.22381401],\n",
              "       [-0.2444114 , -0.20960057],\n",
              "       [-0.26666602, -0.22258666],\n",
              "       [-0.280888  , -0.21057191],\n",
              "       [-0.22972256, -0.20747927],\n",
              "       [-0.26632282, -0.2147327 ],\n",
              "       [-0.25082332, -0.23013523],\n",
              "       [-0.25890422, -0.21757881],\n",
              "       [-0.24603227, -0.20641916],\n",
              "       [-0.23987256, -0.2122017 ],\n",
              "       [-0.2585137 , -0.21962553],\n",
              "       [-0.21128897, -0.22110683],\n",
              "       [-0.2621833 , -0.21162267],\n",
              "       [-0.2156506 , -0.24813245],\n",
              "       [-0.22388993, -0.22668672],\n",
              "       [-0.25057745, -0.21404704],\n",
              "       [-0.25510183, -0.19879536],\n",
              "       [-0.25686133, -0.22378781],\n",
              "       [-0.25588873, -0.22722137],\n",
              "       [-0.2632831 , -0.21580102],\n",
              "       [-0.25552332, -0.23212478],\n",
              "       [-0.24522677, -0.24890181],\n",
              "       [-0.2613049 , -0.23440191],\n",
              "       [-0.2562112 , -0.21531194],\n",
              "       [-0.23658702, -0.23329736],\n",
              "       [-0.24180445, -0.22817342],\n",
              "       [-0.23721325, -0.21898234],\n",
              "       [-0.25245878, -0.2177226 ],\n",
              "       [-0.22953933, -0.23549634],\n",
              "       [-0.25102794, -0.22112456],\n",
              "       [-0.25135067, -0.23144855],\n",
              "       [-0.26451162, -0.2156885 ],\n",
              "       [-0.22078267, -0.26410332],\n",
              "       [-0.27402553, -0.20652169],\n",
              "       [-0.24741253, -0.23011617],\n",
              "       [-0.23280619, -0.22728662],\n",
              "       [-0.26870623, -0.2069682 ],\n",
              "       [-0.26360208, -0.21022944],\n",
              "       [-0.25383133, -0.2178459 ],\n",
              "       [-0.25321704, -0.22539733],\n",
              "       [-0.2593189 , -0.21083336],\n",
              "       [-0.27300096, -0.20356905],\n",
              "       [-0.25121638, -0.20666306],\n",
              "       [-0.26431942, -0.21584442],\n",
              "       [-0.26294085, -0.2000475 ],\n",
              "       [-0.26619127, -0.22681695],\n",
              "       [-0.27247778, -0.20953378],\n",
              "       [-0.21977516, -0.22455275],\n",
              "       [-0.26409563, -0.24364394],\n",
              "       [-0.25911656, -0.20104937],\n",
              "       [-0.25392625, -0.21790235],\n",
              "       [-0.26651624, -0.20296964],\n",
              "       [-0.2529742 , -0.23216695],\n",
              "       [-0.2590568 , -0.21062917],\n",
              "       [-0.23965108, -0.24317518],\n",
              "       [-0.24817674, -0.23730247],\n",
              "       [-0.23389976, -0.21874577],\n",
              "       [-0.22340527, -0.21558028],\n",
              "       [-0.26830536, -0.20277748],\n",
              "       [-0.24994987, -0.22462685],\n",
              "       [-0.2560501 , -0.22430462],\n",
              "       [-0.2050602 , -0.24399427],\n",
              "       [-0.25926518, -0.24489273],\n",
              "       [-0.23099156, -0.21123269],\n",
              "       [-0.25958914, -0.21289654],\n",
              "       [-0.25957933, -0.22027594],\n",
              "       [-0.21221954, -0.24212894],\n",
              "       [-0.23956376, -0.21109511],\n",
              "       [-0.26273808, -0.21770662],\n",
              "       [-0.26711056, -0.21063036],\n",
              "       [-0.22337554, -0.23349398],\n",
              "       [-0.26041546, -0.23637787],\n",
              "       [-0.2428292 , -0.20937327],\n",
              "       [-0.25253704, -0.22239259],\n",
              "       [-0.26626256, -0.23240322],\n",
              "       [-0.22958112, -0.22924301],\n",
              "       [-0.24707972, -0.22890413],\n",
              "       [-0.24632853, -0.22364071],\n",
              "       [-0.2507414 , -0.21038216],\n",
              "       [-0.2638582 , -0.22012895],\n",
              "       [-0.23513775, -0.24530539],\n",
              "       [-0.2361632 , -0.21515818],\n",
              "       [-0.25165543, -0.23297428],\n",
              "       [-0.22383161, -0.2519188 ],\n",
              "       [-0.25955662, -0.22449718],\n",
              "       [-0.25596765, -0.19924185],\n",
              "       [-0.25282034, -0.21486227],\n",
              "       [-0.21359862, -0.21953693],\n",
              "       [-0.24339297, -0.24009433],\n",
              "       [-0.22164436, -0.23410097],\n",
              "       [-0.26364005, -0.20616609],\n",
              "       [-0.25922439, -0.21047688],\n",
              "       [-0.26241323, -0.21151775],\n",
              "       [-0.24804041, -0.23036112],\n",
              "       [-0.2570515 , -0.20792727],\n",
              "       [-0.22806899, -0.22121584],\n",
              "       [-0.25828397, -0.21560793],\n",
              "       [-0.2693223 , -0.20571308],\n",
              "       [-0.24330933, -0.22229677],\n",
              "       [-0.24694219, -0.2131391 ],\n",
              "       [-0.26600838, -0.20003225],\n",
              "       [-0.26571253, -0.21821721],\n",
              "       [-0.2594253 , -0.2168516 ],\n",
              "       [-0.24858165, -0.2267271 ],\n",
              "       [-0.23629577, -0.21780989],\n",
              "       [-0.22173022, -0.25697994],\n",
              "       [-0.24530867, -0.22272064],\n",
              "       [-0.2509139 , -0.2287788 ],\n",
              "       [-0.23723146, -0.2237343 ],\n",
              "       [-0.22947718, -0.23121081],\n",
              "       [-0.24886873, -0.21968745],\n",
              "       [-0.26473105, -0.22130571],\n",
              "       [-0.25787142, -0.21469255],\n",
              "       [-0.20583494, -0.2136591 ],\n",
              "       [-0.28381383, -0.20109312],\n",
              "       [-0.25070724, -0.22871883]], dtype=float32), label_ids=array([0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
              "       1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "       1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
              "       0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
              "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
              "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
              "       0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
              "       0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1]), metrics={'test_loss': 0.6945685744285583, 'test_accuracy': 0.444, 'test_f1': 0.5813253012048193, 'test_precision': 0.4346846846846847, 'test_recall': 0.8772727272727273, 'test_runtime': 32.7076, 'test_samples_per_second': 15.287, 'test_steps_per_second': 1.926})"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    }
  ]
}